{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: MAP Classifier\n",
    "\n",
    "In this assignment you will implement a few of the MAP classifiers learned in class.\n",
    "\n",
    "## Read the following instructions carefully:\n",
    "\n",
    "1. This jupyter notebook contains all the step by step instructions needed for this part of the exercise.\n",
    "2. Write vectorized code whenever possible.\n",
    "3. You are responsible for the correctness of your code and should add as many tests as you see fit. Tests will not be graded nor checked.\n",
    "4. Write your functions in the provided `hw3.py` python module only. All the logic you write is imported and used in this jupyter notebook.\n",
    "5. You are allowed to use functions and methods from the [Python Standard Library](https://docs.python.org/3/library/) and [numpy](https://www.numpy.org/devdocs/reference/) only. Any other imports detected in `hw3.py` will earn you the grade of 0, even if you only used them for testing.\n",
    "6. Your code must run without errors. During the environment setup, you were given a specific version of `numpy` to install. Changes of the configuration we provided are at your own risk. Code that cannot run will also earn you the grade of 0.\n",
    "7. Write your own code. Cheating will not be tolerated. \n",
    "8. Submission includes the `hw3.py` file and this notebook. Answers to qualitative questions should be written in markdown cells (with $\\LaTeX$ support).\n",
    "9. You are allowed to include additional functions.\n",
    "10. Submission: zip only the completed jupyter notebook and the python file `hw3.py`. Do not include the data or any directories. Name the file `ID1_ID2.zip` and submit only one copy of the assignment.\n",
    "\n",
    "## In this exercise you will perform the following:\n",
    "1. Implement a Naive Bayeas Classifier based on Multi Normal distribution\n",
    "1. Implement a Full Bayes Classifier based on Multi-Normal distribution\n",
    "1. Implement a Distcrete Naive Bayes Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hw3 import *\n",
    "\n",
    "# Make the notebook automatically reload external python modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Normal Naive Bayes Classifier Vs Normal Full Bayes Classifier\n",
    "In the following section we are going to compare 2 models on a given dataset. <br>\n",
    "The 2 classifiers we are going to test are:\n",
    "1. Naive Bayes classifer.<br>\n",
    "1. Full Bayes classifier.<br>\n",
    "Recall that a Naive Bayes classifier makes the following assumption :<br> \n",
    "## $$ p(x_1, x_2, ..., x_n|A_j) = \\Pi p(x_i | A_j) $$\n",
    "But the full Bayes classifier will not make this assumption.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data Story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a farway land called **Randomistan** there is a rare animal called the **Randomammal**.<br> \n",
    "We have gathered data about this unique animal to help the **randomian** researchers in observing this beast. <br>\n",
    "For a 1000 days straight we have measured the temparture and the humidty in Randomistan and wether the Randomammal was spotted or not. <br>\n",
    "The well known randomian **Bob** is a bit of a lazy researcher so he likes to keep things simple, and so he assumes that the temperature and the humidity are independent given the class. <br>\n",
    "**Alice** on the other hand is a hard working researcher and does not make any assumptions, she's young and is trying to gain some fame in the randomian community.\n",
    "\n",
    "The dataset contains 2 features(**Temperature**, **Humidty**) along side a binary label (**Spotted**) for each instance.<br>\n",
    "\n",
    "We are going to test 2 different classifiers :\n",
    "* Naive Bayes Classifier (Bob)\n",
    "* Full Bayes Classifier. (Alice)\n",
    "\n",
    "Both of our researchers asumme that our features are norammly distributed. But while Bob with his Naive classifier will assume that the features are independet, Alice and her Full Bayes classifier will not make this assumption.<br><br>\n",
    "Let's start off by loading the data (train, test) into a pandas dataframe and then converting them\n",
    "into numpy arrays.<br>\n",
    "The datafiles located in the data folder are :\n",
    "- randomammal_train.csv\n",
    "- randomammal_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test set into a pandas dataframe and convert them into a numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "Draw a scatter plot of the training data where __x__=Temerature and **y**=Humidity. <br>\n",
    "Use color to distinguish points from different classes.<br>\n",
    "Stop for a minute to think about Alice and Bob's approaches and which one you expect to work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bob's Naive Model\n",
    "\n",
    "Start with implementing the [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution) probability density function in your hw3.py: \n",
    "$$ \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\cdot e ^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} $$\n",
    "Where :\n",
    "* $\\mu$ is the distribution mean.\n",
    "* $\\sigma$ is the distribution standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that when using the naive assumption, we assume our features are indepenent given the class. Meaning:\n",
    "$$ P(x_1, x_2 | Y) = p(x_1 | Y) \\cdot p(x_2 | Y)$$\n",
    "Since we assume our features are normally distributed we need to find the mean and std for each feature in order for us to compute those probabilites.<br>\n",
    "Implement the **NaiveNormalClassDistribution** in hw3.py and build a distribution object for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the a NaiveNormalClassDistribution for each class.\n",
    "naive_normal_CD_0 = 0\n",
    "naive_normal_CD_1 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the **MAPClassifier** class in hw3.py and build a MAPClassifier object contating the 2 distribution objects you just made above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_normal_classifier = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model\n",
    "Implement the **compute_accuracy** function in your hw3.py file.<br>\n",
    "Use that function and the 2 distribution objects you created to compute the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the naive model accuracy and store it in the naive accuracy variable.\n",
    "naive_accuracy = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alice's Full Model\n",
    "\n",
    "Start with Implementing the [multivariate normal](https://en.wikipedia.org/wiki/Multivariate_normal_distribution) distribution probability density function in your hw3.py file.\n",
    "\n",
    "## $$ (2\\pi)^{-\\frac{d}{2}} det(\\Sigma )^{-\\frac{1}{2}} \\cdot e ^{-\\frac{1}{2}(x-\\mu)^T \\Sigma ^ {-1} (x - \\mu) }$$\n",
    "\n",
    "Where : \n",
    "* $\\mu$ is the distribution mean vector. (length 2 in our case)\n",
    "* $\\Sigma$ Is the distribution covarince matrix. (size 2x2 in our case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the full bayes model we will not make any simplyfing assumptions, meaning, we will use a multivariate normal distribution. <br>\n",
    "And so, we'll need to compute the mean of each feature and to compute the covariance between the features to build the covariance matrix.\n",
    "Implement the **MultiNormalClassDistribution** in hw3.py and build a distribution object for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the a MultiNormalClassDistribution for each class.\n",
    "multi_normal_CD_0 = 0\n",
    "multi_normal_CD_1 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build a MAPClassifier object contating the 2 distribution objects you just made above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_normal_classifier = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model\n",
    "Use the **compute_accuracy** function and the 2 distribution objects you created to compute the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the naive model accuracy and store it in the naive accuracy variable.\n",
    "full_accuracy = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a plot bar to showcase the models accuracy. 1 bar for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of accuracy of each model side by side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build a discrete naive Bayes based classifier using **Laplace** smoothing.\n",
    "In the recitation, we saw how to compute the probability for each attribute value under each class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(x_j | A_i) = \\frac{n_{ij} + 1}{n_i + |V_j|} $$\n",
    "Where:\n",
    "* $n_{ij}$ The number of training instances with the class $A_i$ and the value $x_j$ in the relevant attribute.\n",
    "* $n_i$ The number of training instances with the class $A_i$\n",
    "* $|V_j|$ The number of possible values of the relevant attribute.\n",
    "\n",
    "In order to compute the likelihood we assume:\n",
    "$$ P(x| A_i) = \\prod\\limits_{j=1}^{n}P(x_j|A_i) $$\n",
    "\n",
    "And to classify an instance we will choose : \n",
    "$$\\arg\\!\\max\\limits_{i} P(A_i) \\cdot P(x | A_i)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "We will try to predict breast cancer again only this time from a different dataset, \n",
    "<br> you can read about the dataset here : [Breast Cancer Dataset](https://archive.ics.uci.edu/ml/datasets/breast+cancer)<br>\n",
    "Load the training set and test set provided for you in the data folder.\n",
    " - breast_trainset.csv\n",
    " - breast_testset.csv\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test set into a pandas dataframe and convert them into a numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build A Discrete Naive Bayes Distribution for each class\n",
    "Implement the **DiscreteNBClassDistribution** in hw3.py and build a distribution object for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_naive_CD_0 = 0\n",
    "discrete_naive_CD_1 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build a MAPClassifier object contating the 2 distribution objects you just made above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_naive_classifier = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the **compute_accuracy** function and the 2 distribution objects you created to compute the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
